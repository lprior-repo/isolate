//! Done command - Complete work and merge to main
//!
//! This command:
//! 1. Validates we're in a workspace (not main)
//! 2. Checks for uncommitted changes
//! 3. Commits any uncommitted changes
//! 4. Checks for merge conflicts
//! 5. Merges workspace changes to main
//! 6. Logs undo history to .zjj/undo.log
//! 7. Updates linked bead status to completed
//! 8. Keeps workspace for 24h (unless --no-keep specified)
//! 9. Switches back to main

#![cfg_attr(not(test), deny(clippy::unwrap_used))]
#![cfg_attr(not(test), deny(clippy::expect_used))]
#![cfg_attr(not(test), deny(clippy::panic))]

pub mod bead;
pub mod conflict;
pub mod executor;
pub mod filesystem;
pub mod newtypes;
pub mod types;

use std::{
    path::{Path, PathBuf},
    time::SystemTime,
};

use anyhow::Result;
pub use types::{DoneError, DoneOptions, DoneOutput, UndoEntry};
use zjj_core::{json::SchemaEnvelope, WorkspaceState};

use self::conflict::ConflictDetector;
use crate::{
    cli::jj_root,
    commands::{
        context::{detect_location, Location},
        get_session_db,
    },
    session::{SessionStatus, SessionUpdate},
};

/// Run the done command with options
pub async fn run_with_options(options: &DoneOptions) -> Result<()> {
    // Create real dependencies
    let executor = executor::RealJjExecutor::new();
    let root_path = jj_root()
        .await
        .map_err(|e| anyhow::anyhow!("Failed to get JJ root: {e}"))?;
    let mut bead_repo = bead::RealBeadRepository::new(PathBuf::from(root_path));
    let filesystem = filesystem::RealFileSystem::new();

    // Handle detect_conflicts mode early
    if options.detect_conflicts {
        let detector = conflict::JjConflictDetector::new(&executor);
        let result = detector.detect_conflicts().await?;
        if options.format.is_json() {
            println!("{}", serde_json::to_string_pretty(&result)?);
        } else {
            println!("{}", result.summary);
            if !result.existing_conflicts.is_empty() {
                println!("\nExisting conflicts:");
                result.existing_conflicts.iter().for_each(|file| {
                    println!("  - {file}");
                });
            }
            if !result.overlapping_files.is_empty() {
                println!("\nPotential conflicts (files modified in both):");
                result.overlapping_files.iter().for_each(|file| {
                    println!("  - {file}");
                });
            }
            if !result.workspace_only.is_empty() {
                println!(
                    "\nWorkspace-only changes ({} files):",
                    result.workspace_only.len()
                );
                result.workspace_only.iter().take(10).for_each(|file| {
                    println!("  - {file}");
                });
                if result.workspace_only.len() > 10 {
                    println!("  ... and {} more", result.workspace_only.len() - 10);
                }
            }
            if result.merge_likely_safe {
                println!("\nâœ… Merge is likely safe");
            } else {
                println!("\nâš ï¸  Review conflicts before merging");
            }
        }
        if result.has_conflicts() {
            anyhow::bail!("Merge conflicts detected");
        }
        return Ok(());
    }

    let output = execute_done(options, &executor, &mut bead_repo, &filesystem).await?;
    output_result(&output, options.format)?;
    Ok(())
}

/// Core done logic using Railway-Oriented Programming
async fn execute_done(
    options: &DoneOptions,
    executor: &dyn executor::JjExecutor,
    bead_repo: &mut dyn bead::BeadRepository,
    filesystem: &dyn filesystem::FileSystem,
) -> Result<DoneOutput, DoneError> {
    // Phase 1: Validate location (must be in workspace)
    let root = validate_location().await?;
    let workspace_name = get_workspace_name(&root)?;

    // Phase 2: Build preview for dry-run
    let preview = if options.dry_run {
        Some(build_preview(&root, &workspace_name, executor, bead_repo, options).await?)
    } else {
        None
    };

    if options.dry_run {
        return Ok(DoneOutput {
            workspace_name,
            dry_run: true,
            preview,
            session_updated: false,
            ..Default::default()
        });
    }

    // Phase 3: Check uncommitted files
    let uncommitted_files = get_uncommitted_files(&root, executor).await?;

    // Phase 4: Commit uncommitted changes
    let files_committed = if uncommitted_files.is_empty() {
        0
    } else {
        commit_changes(&root, &workspace_name, options.message.as_deref(), executor).await?
    };

    // Phase 5: Check for conflicts
    check_conflicts(&root, executor)
        .await
        .map_err(|err| queue_merge_conflict(err, &workspace_name, bead_repo))?;

    // Phase 5.5: Get pre-merge commit ID (for undo)
    let pre_merge_commit_id = get_current_commit_id(&root, executor).await?;

    // Phase 5.6: Check if pushed to remote (for undo)
    let pushed_to_remote = is_pushed_to_remote(&root, executor).await?;

    // Phase 6: Get commits to merge
    let commits_to_merge = get_commits_to_merge(&root, executor).await?;

    // Phase 7: Merge to main
    merge_to_main(&root, &workspace_name, options.squash, executor)
        .await
        .map_err(|err| queue_merge_conflict(err, &workspace_name, bead_repo))?;

    // Phase 7.5: Log undo history
    log_undo_history(
        &root,
        &workspace_name,
        &pre_merge_commit_id,
        pushed_to_remote,
        filesystem,
    )
    .await?;

    // Phase 8: Update bead status
    let bead_id = get_bead_id_for_workspace(&workspace_name, bead_repo).await?;
    let bead_closed = if let Some(ref bead) = bead_id {
        if options.no_bead_update {
            false
        } else {
            update_bead_status(bead, "closed", bead_repo).await?;
            true
        }
    } else {
        false
    };

    // Phase 8.5: Update session status to Completed
    let session_updated = update_session_status(&workspace_name).await?;

    // Phase 9: Cleanup workspace
    let cleaned = if options.keep_workspace || !options.no_keep {
        false
    } else {
        cleanup_workspace(&root, &workspace_name, filesystem).await?
    };

    Ok(DoneOutput {
        workspace_name,
        bead_id,
        files_committed,
        commits_merged: commits_to_merge.len(),
        merged: true,
        cleaned,
        bead_closed,
        session_updated,
        new_status: if session_updated {
            Some("completed".to_string())
        } else {
            None
        },
        pushed_to_remote,
        dry_run: false,
        preview: None,
        error: None,
    })
}

/// Validate we're in a workspace
async fn validate_location() -> Result<String, DoneError> {
    let root_str = jj_root().await.map_err(|_| DoneError::NotAJjRepo)?;
    let root = PathBuf::from(&root_str);

    let location = detect_location(&root).map_err(|e| DoneError::InvalidState {
        reason: e.to_string(),
    })?;

    match location {
        Location::Workspace { .. } => Ok(root_str),
        Location::Main => {
            let current = std::env::current_dir()
                .map(|p| p.to_string_lossy().to_string())
                .unwrap_or_else(|_| "unknown".to_string());
            Err(DoneError::NotInWorkspace {
                current_location: current,
            })
        }
    }
}

/// Get the current workspace name from location
fn get_workspace_name(root: &str) -> Result<String, DoneError> {
    let location = detect_location(&PathBuf::from(root)).map_err(|e| DoneError::InvalidState {
        reason: e.to_string(),
    })?;

    match location {
        Location::Workspace { name, .. } => Ok(name),
        Location::Main => Err(DoneError::NotInWorkspace {
            current_location: "main".to_string(),
        }),
    }
}

/// Build preview for dry-run mode
async fn build_preview(
    root: &str,
    workspace_name: &str,
    executor: &dyn executor::JjExecutor,
    bead_repo: &dyn bead::BeadRepository,
    options: &DoneOptions,
) -> Result<types::DonePreview, DoneError> {
    let uncommitted_files = get_uncommitted_files(root, executor).await?;
    let commits_to_merge = get_commits_to_merge(root, executor).await?;
    let potential_conflicts = check_potential_conflicts(root, executor).await;
    let bead_to_close = get_bead_id_for_workspace(workspace_name, bead_repo).await?;
    let workspace_path = Path::new(root).join(".zjj/workspaces").join(workspace_name);

    // Run detailed conflict detection if requested
    let conflict_detection = if options.detect_conflicts {
        Some(
            conflict::run_conflict_detection(executor)
                .await
                .map_err(|e| DoneError::InvalidState {
                    reason: format!("Conflict detection failed: {e}"),
                })?,
        )
    } else {
        None
    };

    Ok(types::DonePreview {
        uncommitted_files,
        commits_to_merge,
        potential_conflicts,
        bead_to_close,
        workspace_path: workspace_path.to_string_lossy().to_string(),
        conflict_detection,
    })
}

/// Get list of uncommitted files
async fn get_uncommitted_files(
    _root: &str,
    executor: &dyn executor::JjExecutor,
) -> Result<Vec<String>, DoneError> {
    let output =
        executor
            .run(&["status", "--no-pager"])
            .await
            .map_err(|e: executor::ExecutorError| DoneError::JjCommandFailed {
                command: "jj status".to_string(),
                reason: e.to_string(),
            })?;

    let stdout = output.as_str();
    let files = stdout
        .lines()
        .map(str::trim)
        .filter(|line| {
            line.starts_with("A ")
                || line.starts_with("M ")
                || line.starts_with("D ")
                || line.starts_with("R ")
        })
        .filter_map(|line| line.split_ascii_whitespace().nth(1))
        .map(String::from)
        .collect();

    Ok(files)
}

/// Commit uncommitted changes
async fn commit_changes(
    _root: &str,
    workspace_name: &str,
    message: Option<&str>,
    executor: &dyn executor::JjExecutor,
) -> Result<usize, DoneError> {
    let default_msg = format!("Complete work on {workspace_name}");
    let msg = message.unwrap_or(&default_msg);

    let output =
        executor
            .run(&["commit", "-m", msg])
            .await
            .map_err(|e: executor::ExecutorError| DoneError::CommitFailed {
                reason: e.to_string(),
            })?;

    // Count files committed
    let stdout = output.as_str();
    let count = stdout.matches("committed").count();

    Ok(count.max(1))
}

/// Check for merge conflicts
async fn check_conflicts(root: &str, executor: &dyn executor::JjExecutor) -> Result<(), DoneError> {
    let conflicts = check_potential_conflicts(root, executor).await;

    if !conflicts.is_empty() {
        return Err(DoneError::MergeConflict { conflicts });
    }

    Ok(())
}

fn queue_merge_conflict(
    error: DoneError,
    workspace_name: &str,
    _bead_repo: &dyn bead::BeadRepository,
) -> DoneError {
    // This is problematic because we can't easily await inside map_err without more refactoring
    // For now, we'll just log that we would have queued it.
    // Ideally this whole flow should be refactored to handle async error recovery.
    if matches!(error, DoneError::MergeConflict { .. }) {
        tracing::warn!(
            "Merge conflict detected for workspace {}. Conflict queuing should be handled.",
            workspace_name
        );
    }
    error
}

#[allow(dead_code)]
async fn queue_workspace_conflict(
    workspace_name: &str,
    bead_repo: &dyn bead::BeadRepository,
) -> Result<(), DoneError> {
    let queue_db = Path::new(".zjj/queue.db");
    let queue =
        zjj_core::MergeQueue::open(queue_db)
            .await
            .map_err(|e| DoneError::InvalidState {
                reason: format!("Failed to open merge queue: {e}"),
            })?;

    let existing =
        queue
            .get_by_workspace(workspace_name)
            .await
            .map_err(|e| DoneError::InvalidState {
                reason: format!("Failed to read merge queue: {e}"),
            })?;
    if existing.is_some() {
        return Ok(());
    }

    let env_bead = std::env::var("ZJJ_BEAD_ID").ok();
    let bead_id = env_bead.or({
        // We need a way to call this async here if we wanted to use it
        // but since we are refactoring, we'll just use the env var or None for now
        // to avoid complex async recursion issues in this specific spot.
        None
    });

    // If we really need the bead_id from repo, we'd need to have passed it in or await it
    let bead_id = if bead_id.is_none() {
        get_bead_id_for_workspace(workspace_name, bead_repo)
            .await
            .ok()
            .flatten()
    } else {
        bead_id
    };

    let agent_id = std::env::var("ZJJ_AGENT_ID").ok();

    queue
        .add(workspace_name, bead_id.as_deref(), 5, agent_id.as_deref())
        .await
        .map(|_| ())
        .map_err(|e| DoneError::InvalidState {
            reason: format!("Failed to queue merge conflict: {e}"),
        })
}

/// Check for potential conflicts by checking divergent changes
async fn check_potential_conflicts(
    _root: &str,
    executor: &dyn executor::JjExecutor,
) -> Vec<String> {
    let detector = conflict::JjConflictDetector::new(executor);

    match detector.detect_conflicts().await {
        Ok(result) => {
            // Combine existing conflicts and overlapping files
            let mut conflicts = result.existing_conflicts;
            conflicts.extend(result.overlapping_files);
            conflicts
        }
        Err(e) => {
            // Log error but don't fail - conflict detection is best-effort
            // Return empty to allow merge to proceed (conflicts will be caught during merge)
            eprintln!("Warning: conflict detection failed: {e}");
            Vec::new()
        }
    }
}

/// Get commits that will be merged
async fn get_commits_to_merge(
    _root: &str,
    executor: &dyn executor::JjExecutor,
) -> Result<Vec<types::CommitInfo>, DoneError> {
    let output = executor
        .run(&[
            "log",
            "-r",
            "@..@-",
            "--no-graph",
            "-T",
            r#"change_id ++ "\n" ++ commit_id ++ "\n" ++ description ++ "\n" ++ committer.timestamp() ++ "\n""#,
        ])
        .await
        .map_err(|e: executor::ExecutorError| DoneError::JjCommandFailed {
            command: "jj log".to_string(),
            reason: e.to_string(),
        })?;

    let stdout = output.as_str();
    let mut commits = Vec::new();
    let mut lines = stdout.lines().peekable();

    while lines.peek().is_some() {
        let change_id = lines.next().unwrap_or("").trim().to_string();
        let commit_id = lines.next().unwrap_or("").trim().to_string();
        let description = lines.next().unwrap_or("").trim().to_string();
        let timestamp = lines.next().unwrap_or("").trim().to_string();

        if !change_id.is_empty() {
            commits.push(types::CommitInfo {
                change_id,
                commit_id,
                description,
                timestamp,
            });
        }
    }

    Ok(commits)
}

/// Merge workspace changes to main using rebase
async fn merge_to_main(
    _root: &str,
    workspace_name: &str,
    _squash: bool,
    executor: &dyn executor::JjExecutor,
) -> Result<(), DoneError> {
    // First, forget the workspace
    let result = executor.run(&["workspace", "forget", workspace_name]).await;

    match result {
        Ok(_) => Ok(()),
        Err(e) => {
            let error_msg = e.to_string();
            Err(DoneError::MergeFailed { reason: error_msg })
        }
    }
}

/// Get bead ID for a workspace using the bead repository
async fn get_bead_id_for_workspace(
    workspace_name: &str,
    bead_repo: &dyn bead::BeadRepository,
) -> Result<Option<String>, DoneError> {
    use newtypes::WorkspaceName;

    let workspace =
        WorkspaceName::new(workspace_name.to_string()).map_err(|e| DoneError::InvalidState {
            reason: e.to_string(),
        })?;

    bead_repo
        .find_by_workspace(&workspace)
        .await
        .map(|opt| opt.map(|id| id.as_str().to_string()))
        .map_err(|e| DoneError::BeadUpdateFailed {
            reason: e.to_string(),
        })
}

/// Update bead status in the database using the bead repository
async fn update_bead_status(
    bead_id: &str,
    new_status: &str,
    bead_repo: &mut dyn bead::BeadRepository,
) -> Result<(), DoneError> {
    use newtypes::BeadId;

    let bead_id_newtype =
        BeadId::new(bead_id.to_string()).map_err(|e| DoneError::BeadUpdateFailed {
            reason: e.to_string(),
        })?;

    bead_repo
        .update_status(&bead_id_newtype, new_status)
        .await
        .map_err(|e| DoneError::BeadUpdateFailed {
            reason: e.to_string(),
        })
}

/// Cleanup the workspace directory
async fn cleanup_workspace(
    root: &str,
    workspace_name: &str,
    filesystem: &dyn filesystem::FileSystem,
) -> Result<bool, DoneError> {
    let workspace_path = Path::new(root).join(".zjj/workspaces").join(workspace_name);

    if filesystem.exists(&workspace_path).await {
        filesystem
            .remove_dir_all(&workspace_path)
            .await
            .map_err(|e| DoneError::CleanupFailed {
                reason: format!("Failed to remove workspace {workspace_name}: {e}"),
            })?;
        Ok(true)
    } else {
        Ok(false)
    }
}

/// Update session status to Completed and state to Merged
async fn update_session_status(workspace_name: &str) -> Result<bool, DoneError> {
    let db = get_session_db()
        .await
        .map_err(|e| DoneError::InvalidState {
            reason: format!("Failed to open session database: {e}"),
        })?;

    let update = SessionUpdate {
        status: Some(SessionStatus::Completed),
        state: Some(WorkspaceState::Merged),
        branch: None,
        last_synced: None,
        metadata: None,
    };

    db.update(workspace_name, update)
        .await
        .map_err(|e| DoneError::InvalidState {
            reason: format!("Failed to update session status: {e}"),
        })?;

    Ok(true)
}

/// Output the result in the appropriate format
fn output_result(result: &DoneOutput, format: zjj_core::OutputFormat) -> Result<()> {
    if format.is_json() {
        let envelope = SchemaEnvelope::new("done-response", "single", result);
        println!("{}", serde_json::to_string_pretty(&envelope)?);
    } else if result.dry_run {
        println!(
            "ðŸ” Dry-run preview for workspace: {}",
            result.workspace_name
        );
        if let Some(ref preview) = result.preview {
            if !preview.uncommitted_files.is_empty() {
                println!("  Files to commit:");
                preview.uncommitted_files.iter().for_each(|file| {
                    println!("    - {file}");
                });
            }
            if !preview.commits_to_merge.is_empty() {
                println!("  Commits to merge: {}", preview.commits_to_merge.len());
            }
            if let Some(ref bead) = preview.bead_to_close {
                println!("  Bead to close: {bead}");
            }
            // Display conflict detection results if available
            if let Some(ref conflict_detection) = preview.conflict_detection {
                println!();
                print!("{}", conflict_detection.to_text_output());
            }
        }
    } else {
        println!("âœ… Workspace '{}' completed", result.workspace_name);
        if result.merged {
            println!("  Merged {} commits to main", result.commits_merged);
        }
        if result.files_committed > 0 {
            println!("  Committed {} files", result.files_committed);
        }
        if result.cleaned {
            println!("  Workspace cleaned up");
        }
        if result.bead_closed {
            println!("  Bead status updated to closed");
        }
        if result.session_updated {
            println!("  Session status updated to completed");
        }
        // Post-command workflow guidance
        println!();
        println!("NEXT: Start new work with:");
        println!("  zjj spawn <bead-id>   # Create isolated workspace for new task");
        println!("  br ready              # See available work items");
    }
    Ok(())
}

/// Get current commit ID (before merge)
async fn get_current_commit_id(
    _root: &str,
    executor: &dyn executor::JjExecutor,
) -> Result<String, DoneError> {
    let output = executor
        .run(&["log", "-r", "@", "--no-graph", "-T", "commit_id"])
        .await
        .map_err(|e: executor::ExecutorError| DoneError::JjCommandFailed {
            command: "jj log".to_string(),
            reason: e.to_string(),
        })?;

    Ok(output.as_str().trim().to_string())
}

/// Check if changes have been pushed to remote
async fn is_pushed_to_remote(
    _root: &str,
    executor: &dyn executor::JjExecutor,
) -> Result<bool, DoneError> {
    let output =
        executor
            .run(&["log", "-r", "@-"])
            .await
            .map_err(|e: executor::ExecutorError| DoneError::JjCommandFailed {
                command: "jj log".to_string(),
                reason: e.to_string(),
            })?;

    Ok(output.as_str().trim().is_empty())
}

/// Log undo history to .zjj/undo.log
async fn log_undo_history(
    root: &str,
    workspace_name: &str,
    pre_merge_commit_id: &str,
    pushed_to_remote: bool,
    filesystem: &dyn filesystem::FileSystem,
) -> Result<(), DoneError> {
    let undo_log_path = Path::new(root).join(".zjj/undo.log");

    let undo_entry = UndoEntry {
        session_name: workspace_name.to_string(),
        commit_id: String::new(),
        pre_merge_commit_id: pre_merge_commit_id.to_string(),
        timestamp: SystemTime::now()
            .duration_since(SystemTime::UNIX_EPOCH)
            .map_err(|e| DoneError::InvalidState {
                reason: format!("System time error: {e}"),
            })?
            .as_secs(),
        pushed_to_remote,
        status: "completed".to_string(),
    };

    let json = serde_json::to_string(&undo_entry).map_err(|e| DoneError::InvalidState {
        reason: format!("Failed to serialize undo entry: {e}"),
    })?;

    let mut content = if filesystem.exists(&undo_log_path).await {
        filesystem
            .read_to_string(&undo_log_path)
            .await
            .map_err(|e| DoneError::InvalidState {
                reason: format!("Failed to read undo log: {e}"),
            })?
    } else {
        String::new()
    };
    content.push_str(&json);
    content.push('\n');

    filesystem
        .write(&undo_log_path, &content)
        .await
        .map_err(|e| DoneError::InvalidState {
            reason: format!("Failed to write undo log: {e}"),
        })?;

    Ok(())
}
