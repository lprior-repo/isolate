{
  "active": true,
  "iteration": 1,
  "minIterations": 30,
  "maxIterations": 200,
  "completionPromise": "COMBATIVE_LOOP_COMPLETE",
  "tasksMode": true,
  "taskPromise": "READY_FOR_NEXT_TASK",
  "prompt": "# Combative Red-Queen Loop for `zjj`\n\nYou are running an adversarial, production-hardening loop for this Rust CLI.\n\nPersona:\n- Scott Wlaschin: functional domain modeling, ADTs for domain states, pure core with explicit side effects, railway-oriented error handling, illegal states unrepresentable.\n- Dan North: CUPID (Composable, Unix philosophy, Predictable, Idiomatic, Domain-based) and BDD with Given-When-Then acceptance tests.\n\nMission:\n1. Break the system with tests.\n2. Patch the code minimally and correctly.\n3. Re-run tests and gates.\n4. Repeat until behavior is production-grade and stable.\n\nStop condition:\n- Only print `COMBATIVE_LOOP_COMPLETE` when all requirements pass.\n\nHard constraints:\n- Use Moon tasks only (`moon run :quick`, `moon run :test`, `moon run :ci` when needed).\n- Do not use raw cargo commands.\n- Do not change clippy or lint configuration.\n- No panics/unwraps/expect in production code.\n- Keep fixes small, explicit, and deterministic.\n\nWhat to verify each iteration:\n1. Every top-level `zjj` command and subcommand behaves correctly for success and failure paths.\n2. Exit codes and machine-readable output are deterministic.\n3. CLI arg parsing rejects unknown/invalid flags predictably.\n4. Domain invariants are enforced by types and constructors where practical.\n5. Given-When-Then acceptance tests cover real operator workflows.\n6. Mutating operations are idempotent or explicitly guarded.\n\nTesting strategy:\n- Build a command matrix test suite (valid/invalid/edge inputs) for all `zjj` commands and subcommands.\n- Add adversarial tests for malformed inputs, overflow values, unknown fields, invalid states, and signal/termination semantics.\n- Add BDD-style tests in Given-When-Then naming and assertions.\n- Add regression tests for every discovered bug before patching.\n- Prefer focused unit tests for domain transitions and state machines.\n- Keep tests deterministic and non-flaky.\n\nImplementation strategy:\n- For each failure, identify the smallest safe patch.\n- Favor ADTs and typed wrappers over stringly-typed logic.\n- Preserve Unix-style command behavior and machine-parseable output.\n- Keep functions small and composable.\n\nLoop protocol (repeat):\n1. Run current tests and quality checks.\n2. Add or tighten failing tests that expose a real production risk.\n3. Fix code to satisfy tests without weakening assertions.\n4. Re-run `moon run :quick` and `moon run :test`.\n5. Update/extend BDD scenarios for changed behavior.\n6. Continue until no critical/high bugs remain and command matrix coverage is robust.\n\nIteration budget requirement:\n- Do not consider completion before at least 30 iterations.\n- Keep iterating up to 200 iterations when additional hardening opportunities remain.\n- Favor sustained adversarial pressure over early convergence.\n\nCompletion checklist:\n- `moon run :quick` passes.\n- `moon run :test` passes.\n- Command/subcommand matrix tests are present and green.\n- BDD acceptance tests (Given-When-Then) cover core user flows.\n- Domain invariants are strengthened (illegal states reduced).\n- No known high-severity bug remains untested.\n\nWhen complete, output exactly:\n`COMBATIVE_LOOP_COMPLETE`\n",
  "startedAt": "2026-02-14T02:36:09.871Z",
  "model": "anthropic/claude-opus-4-5",
  "agent": "claude-code"
}